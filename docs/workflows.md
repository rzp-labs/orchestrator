# Workflows

Available workflows in Orchestrator.

## Overview

Orchestrator provides AI-powered workflows for tactical product development tasks. Each workflow connects to external tools, delegates analysis to specialized agents, and automates repetitive tasks.

**Current workflows**:
- **Support Triage** - Automated validity and severity assessment
- **Issue Investigation** - Research Linear history, identify patterns, provide evidence-based recommendations

## Support Triage Workflow

Automates investigation of support tickets in Linear.

### What It Does

1. **Fetches ticket** from Linear using GraphQL API
2. **Analyzes validity** - Delegates to `analysis-expert` agent
   - Is this a valid bug/issue?
   - Is it actionable (sufficient info)?
   - What additional context is needed?
3. **Assesses severity** - Delegates to `bug-hunter` agent
   - Severity level (P0/P1/P2/P3)
   - Complexity estimate (simple/medium/complex)
   - Required expertise areas
4. **Updates Linear** - Adds AI analysis as comment and sets priority

### Usage

**Basic usage**:
```bash
uv run orchestrator triage <ticket-id>
```

**Example**:
```bash
uv run orchestrator triage ABC-123
```

**Expected output**:
```
Fetching ticket ABC-123...
✓ Ticket fetched: "User login fails with 500 error"

Analyzing validity...
✓ Validity analysis complete (12s)
  - Valid issue: Yes
  - Actionable: Yes
  - Missing context: None

Assessing severity...
✓ Severity assessment complete (8s)
  - Priority: P1 (High)
  - Complexity: Medium
  - Expertise: Backend, Database

Updating Linear...
✓ Comment added
✓ Priority set to P1

✓ Triage complete for ABC-123 (23s total)
```

### When to Use

**Use triage workflow when**:
- Support ticket needs investigation
- Technical context required for priority decision
- Volume of tickets makes manual triage time-prohibitive
- PM needs engineer-level analysis without engineer availability

**Don't use when**:
- Ticket is straightforward (obvious priority/validity)
- Immediate response needed (triage takes 20-30 seconds)
- Ticket lacks basic information (LLM can't analyze empty descriptions)

### How It Works

#### Step 1: Fetch Ticket

```python
# Executes via Linear GraphQL API
ticket_data = fetch_issue(ticket_id)
```

Retrieves full ticket data including:
- Title and description
- Current priority and state
- Team information
- Reporter information

#### Step 2: Validity Analysis

Delegates to `analysis-expert` agent:

```python
validity_result = await run_agent(
    agent_name="analysis-expert",
    task_description=f"""
    Analyze this support issue for validity and actionability:

    {ticket_json}

    Determine:
    1. Is this a valid bug/issue?
    2. Is it actionable (sufficient info)?
    3. What additional context is needed?
    """
)
```

Agent response includes:
- **is_valid**: Boolean - whether issue is legitimate
- **is_actionable**: Boolean - whether enough info to act
- **missing_context**: List of additional info needed
- **reasoning**: Explanation of determination

#### Step 3: Severity Assessment

Delegates to `bug-hunter` agent:

```python
severity_result = await run_agent(
    agent_name="bug-hunter",
    task_description=f"""
    Estimate complexity and severity of this issue:

    {ticket_json}

    Validity analysis: {validity_result}

    Provide:
    1. Severity (P0/P1/P2/P3)
    2. Estimated complexity (simple/medium/complex)
    3. Required expertise areas
    """
)
```

Agent response includes:
- **severity**: P0 (critical) through P3 (low)
- **complexity**: Simple/Medium/Complex
- **required_expertise**: List of skills needed
- **reasoning**: Explanation of assessment

#### Step 4: Update Linear

Updates ticket with AI analysis:

```python
priority_level = severity_to_priority(severity.severity)
update_issue(ticket_id, priority_level, comment)
```

Comment format:
```markdown
## AI Triage Analysis

**Validity**: Valid, Actionable
**Severity**: P1 (High Priority)
**Complexity**: Medium
**Required Expertise**: Backend, Database

### Analysis
[Reasoning from agents]

### Recommendations
[Next steps from agents]

---
*Generated by Orchestrator*
```

### Error Handling

**Ticket not found**:
```
Error: Ticket ABC-123 not found
Verify ticket ID is correct and accessible with linear-cli
```

**Linear API failure**:
```
Error: Linear API request failed
Check LINEAR_API_KEY environment variable is set
```

**Agent delegation timeout**:
```
Warning: Agent analysis timed out (>60s)
Retrying with simpler prompt...
```

**Invalid JSON response**:
```
Warning: Agent returned invalid JSON
Using defensive parsing to extract data...
```

All errors are logged to `logs/triage_<ticket-id>.log` for debugging.

### Performance

**Typical execution time**: 20-30 seconds
- Fetch ticket: 2-3 seconds
- Validity analysis: 10-15 seconds
- Severity assessment: 8-12 seconds
- Update Linear: 2-3 seconds

**Optimization**:
- Analyses run in parallel where possible
- Timeout limits prevent hanging (60 seconds max per agent)

### Metrics

Hooks automatically collect metrics in `logs/triage_metrics.jsonl`:

```json
{
  "ticket_id": "ABC-123",
  "duration": 23.5,
  "agents_used": ["analysis-expert", "bug-hunter"],
  "success": true,
  "timestamp": "2025-10-26T10:30:00Z"
}
```

Used for:
- Performance monitoring
- Success rate tracking
- Workflow optimization

## Issue Investigation Workflow

Researches Linear issue history, identifies patterns, and provides evidence-based recommendations with mandatory citations.

### What It Does

1. **Fetches issue** from Linear via GraphQL API
2. **Researches Linear history** - Find similar issues by labels, components, text patterns
3. **Identifies patterns** - Resolution patterns, team expertise, common paths
4. **Synthesizes findings** - AI identifies patterns with mandatory citations to source issues
5. **Generates recommendations** - Evidence-based suggestions with traceable sources
6. **Records patterns** - Learning store tracks pattern → recommendation → outcome

### Usage

**Basic usage**:
```bash
uv run orchestrator investigate <issue-id>
```

**Example**:
```bash
uv run orchestrator investigate ABC-456
```

**Expected output**:
```
Fetching issue ABC-456...
✓ Issue fetched: "Database connection timeout"

Researching Linear history...
✓ Found 15 similar issues (18s)

Identifying patterns...
✓ Pattern synthesis complete (22s)
  - 3 similar resolutions found
  - Team member @alice resolved 4 similar issues
  - Common fix: Increase connection pool size

Checking learning store...
✓ Found 2 matching patterns (confidence: 0.85)

Generating recommendations...
✓ Recommendations generated with 8 citations (15s)

Saving results...
✓ Saved to investigation_results/ABC-456.md

✓ Investigation complete for ABC-456 (62s total)
```

### When to Use

**Use investigation workflow when**:
- Issue context would help prioritization or solution
- Similar issues likely exist in project history
- Team needs research synthesis without manual history review
- Pattern learning would improve future recommendations

**Don't use when**:
- Issue is brand new with no similar precedent
- Investigation urgency requires immediate action (takes 60+ seconds)
- Issue description lacks detail for pattern matching

### Output Format

Results saved to `investigation_results/<issue-id>.md`:

```markdown
## Investigation: ABC-456

### Research Sources
- Linear issue history (15 similar issues found)
- Team expertise patterns (4 related resolvers identified)

### Findings

**Finding 1: Similar issue resolved 3 times in past month**
Confidence: High

*Sources:*
- [ABC-400](https://linear.app/team/issue/ABC-400): "Same error pattern, resolved by increasing timeout"
- [ABC-420](https://linear.app/team/issue/ABC-420): "Duplicate root cause identified"
- [ABC-435](https://linear.app/team/issue/ABC-435): "Third occurrence, permanent fix deployed"

**Finding 2: Team member @alice has resolved 4 similar issues**
Confidence: High

*Sources:*
- [ABC-400](https://linear.app/team/issue/ABC-400): Resolved by @alice (2025-10-15)
- [ABC-420](https://linear.app/team/issue/ABC-420): Resolved by @alice (2025-10-25)
- [ABC-430](https://linear.app/team/issue/ABC-430): Resolved by @alice (2025-10-28)
- [ABC-435](https://linear.app/team/issue/ABC-435): Resolved by @alice (2025-11-01)

### Recommendations

**Recommendation: Investigate database connection pooling**
Confidence: High
Reasoning: All 3 similar issues were resolved by adjusting connection pool settings

*Supporting Evidence:*
- [ABC-400](https://linear.app/team/issue/ABC-400): "Increased max_connections from 50 to 100"
- [ABC-420](https://linear.app/team/issue/ABC-420): "Added connection pool timeout of 30s"

**Recommendation: Consult @alice for expertise**
Confidence: High
Reasoning: Demonstrated expertise in resolving this exact issue pattern

*Supporting Evidence:*
- [ABC-400, ABC-420, ABC-430, ABC-435]: 4 successful resolutions

### Missing Data
- Database connection metrics from last 7 days
- Error logs matching this pattern

### Pattern Matches
- Pattern P-123: "Database timeout → connection pool tuning" (confidence: 0.85, 3 prior successes)
- Pattern P-089: "Backend performance → database optimization" (confidence: 0.72, 5 prior successes)

---
*Generated by Orchestrator Investigation*
*Duration: 62s | Citations: 8 | Patterns: 2*
```

### How It Works

#### Step 1: Fetch Issue

```python
# Executes via Linear GraphQL API
issue_data = fetch_issue(issue_id)
```

Retrieves full issue data including:
- Title, description, state
- Labels and components
- Team and assignee
- Comments and timeline

#### Step 2: Research Linear History

Uses `LinearHistoryResearcher` to query for similar issues:

```python
researcher = LinearHistoryResearcher(linear_client)

# Find similar issues by labels, components, text
similar_issues = researcher.find_similar_issues(
    issue=issue_data,
    max_results=50
)

# Identify resolution patterns
patterns = researcher.find_resolution_patterns(similar_issues)

# Track team expertise
expertise = researcher.find_team_expertise(similar_issues)
```

Research includes:
- **Text similarity**: Match description/title text patterns
- **Label matching**: Issues with same labels (bug, backend, database, etc.)
- **Component matching**: Issues in same system components
- **State transitions**: How similar issues were resolved

#### Step 3: Pattern Synthesis

Delegates to AI agent to synthesize patterns:

```python
synthesis_result = await run_agent(
    agent_name="synthesis-master",
    task_description=f"""
    Synthesize patterns from these similar issues:

    Current Issue: {issue_json}
    Similar Issues: {similar_issues_json}

    For each finding, provide:
    1. Finding description
    2. Confidence level (low/medium/high)
    3. Citations (MUST include: source_id, source_url, excerpt)

    Every finding MUST have at least one citation.
    """
)
```

Agent returns structured findings with mandatory citations.

#### Step 4: Generate Recommendations

Delegates to AI agent for recommendations:

```python
recommendations_result = await run_agent(
    agent_name="synthesis-master",
    task_description=f"""
    Based on these findings, provide actionable recommendations:

    Findings: {findings_json}

    For each recommendation, provide:
    1. Recommendation description
    2. Reasoning based on evidence
    3. Confidence level
    4. Citations supporting this recommendation

    Every recommendation MUST cite specific source issues.
    """
)
```

Agent returns evidence-based recommendations with citations.

#### Step 5: Check Learning Store

Queries pattern store for matches:

```python
pattern_store = PatternStore()
matches = pattern_store.find_matching_patterns(
    issue_description=issue_data.description,
    min_confidence=0.7
)
```

Returns patterns that have proven successful in the past.

#### Step 6: Save Results

Saves investigation to markdown file:

```python
output_path = Path(f"investigation_results/{issue_id}.md")
with open(output_path, "w") as f:
    f.write(format_investigation_markdown(result))
```

File includes:
- All findings with citations
- All recommendations with evidence
- Pattern matches from learning store
- Direct links to all cited Linear issues

### Citation Validation

**Pydantic enforces citation requirements**:

```python
class Finding(BaseModel):
    finding: str
    confidence: Literal["low", "medium", "high"]
    citations: list[Citation] = Field(
        ...,
        min_length=1,  # MANDATORY: At least one citation
        description="Sources supporting this finding"
    )

class Recommendation(BaseModel):
    recommendation: str
    reasoning: str
    confidence: Literal["low", "medium", "high"]
    citations: list[Citation] = Field(
        ...,
        min_length=1,  # MANDATORY: At least one citation
        description="Evidence supporting recommendation"
    )
```

If agent response lacks citations, validation fails and workflow retries with error feedback.

### Learning Loop

**Recording patterns**:
```python
# After investigation completes
pattern_store.record_pattern(
    issue_pattern=issue_data.description,
    recommendation=recommendation.text,
    citations=recommendation.citations,
    outcome=None  # Will update when issue closes
)
```

**Updating outcomes**:
```python
# When issue closes (future automation)
pattern_store.update_outcome(
    pattern_id=pattern_id,
    outcome="resolved"  # or "not_resolved"
)
```

Successful patterns gain confidence over time.

### Error Handling

**Issue not found**:
```
Error: Issue ABC-456 not found
Verify issue ID is correct and accessible
```

**No similar issues found**:
```
Warning: No similar issues found in Linear history
Generating recommendations based on issue content only
Note: Recommendations will have lower confidence without historical patterns
```

**Agent response missing citations**:
```
Error: Agent response validation failed - missing citations
Retrying with explicit citation requirements...
```

**Linear API rate limiting**:
```
Warning: Linear API rate limit approaching
Reducing query scope to prevent throttling...
```

All errors logged to `logs/investigation_<issue-id>.log`.

### Performance

**Typical execution time**: 60-90 seconds
- Fetch issue: 2-3 seconds
- Research Linear history: 15-20 seconds (depends on history size)
- Pattern synthesis: 20-25 seconds
- Recommendation generation: 15-20 seconds
- Learning store operations: 3-5 seconds
- Save results: 1-2 seconds

**Optimization**:
- GraphQL queries use pagination to handle large result sets
- Pattern matching uses text indexing for fast searches
- Synthesis and recommendations can run in parallel (future optimization)

### Metrics

Hooks collect metrics in `logs/investigation_metrics.jsonl`:

```json
{
  "issue_id": "ABC-456",
  "duration": 62.5,
  "similar_issues_found": 15,
  "findings_count": 2,
  "recommendations_count": 2,
  "citations_count": 8,
  "pattern_matches": 2,
  "success": true,
  "timestamp": "2025-11-03T10:30:00Z"
}
```

Used for:
- Performance monitoring
- Research quality tracking
- Pattern learning effectiveness
- Citation coverage analysis

## Related Documentation

- **[Architecture](architecture.md)** - How workflows are structured
- **[Adding Workflows](adding_workflows.md)** - Creating new workflows
- **[Hooks & Skills](hooks_and_skills.md)** - Automation patterns
